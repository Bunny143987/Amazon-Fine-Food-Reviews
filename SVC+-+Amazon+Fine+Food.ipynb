{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews  SVC\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and loading the dataset :\n",
    "* Cleaning and handling deduplication of data is already performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakhar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets, neighbors\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('final.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138706</td>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "      <td>b'witti littl book make son laugh loud recit c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138688</td>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "      <td>b'grew read sendak book watch realli rosi movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      Id   ProductId          UserId      ProfileName  \\\n",
       "0  138706  150524  0006641040   ACITT7DI6IDDL  shari zychinski   \n",
       "1  138688  150506  0006641040  A2IW4PEEKO2R0U            Tracy   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     0                       0  positive   939340800   \n",
       "1                     1                       1  positive  1194739200   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                   EVERY book is educational   \n",
       "1  Love the book, miss the hard cover version   \n",
       "\n",
       "                                                Text  \\\n",
       "0  this witty little book makes my son laugh at l...   \n",
       "1  I grew up reading these Sendak books, and watc...   \n",
       "\n",
       "                                         CleanedText  \n",
       "0  b'witti littl book make son laugh loud recit c...  \n",
       "1  b'grew read sendak book watch realli rosi movi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\"\"\", conn)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    42199\n",
       "negative     7801\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling the data :\n",
    "sample_data = data.sample(n=50000)\n",
    "sample_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Based Splitting :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>138683</td>\n",
       "      <td>150501</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "      <td>b'rememb see show air televis year ago child s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>346055</td>\n",
       "      <td>374359</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "      <td>b'twist rumplestiskin captur film star michael...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      Id   ProductId          UserId         ProfileName  \\\n",
       "30   138683  150501  0006641040   AJ46FKXOVC7NR  Nicholas A Mesiano   \n",
       "330  346055  374359  B00004CI84  A344SMIA5JECGM     Vincent P. Ross   \n",
       "\n",
       "     HelpfulnessNumerator  HelpfulnessDenominator     Score       Time  \\\n",
       "30                      2                       2  positive  940809600   \n",
       "330                     1                       2  positive  944438400   \n",
       "\n",
       "                                               Summary  \\\n",
       "30   This whole series is great way to spend time w...   \n",
       "330                            A modern day fairy tale   \n",
       "\n",
       "                                                  Text  \\\n",
       "30   I can remember seeing the show when it aired o...   \n",
       "330  A twist of rumplestiskin captured on film, sta...   \n",
       "\n",
       "                                           CleanedText  \n",
       "30   b'rememb see show air televis year ago child s...  \n",
       "330  b'twist rumplestiskin captur film star michael...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting the sample data using Time column\n",
    "sorted_sample = sample_data.sort_values(by='Time')\n",
    "sorted_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0f34606b15ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Getting the Labels i.e the Score out of the dataframe.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Removing the Labels i.e the Score Column from the dataframe as we wont need it to train a KNN.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msorted_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msorted_sample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sorted_sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Getting the Labels i.e the Score out of the dataframe.\n",
    "y = sorted_sample['Score']\n",
    "# Removing the Labels i.e the Score Column from the dataframe as we wont need it to train a KNN.\n",
    "sorted_sample = sorted_sample.drop(columns='Score')\n",
    "sorted_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set -  (40000, 11)\n",
      "Test Set -  (10000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into Test, Train and Cross-Validation set -\n",
    "x_train = sorted_sample[0:40000]\n",
    "y_train = y[0:40000]\n",
    "x_test = sorted_sample[40000:50000]\n",
    "y_test = y[40000:50000]\n",
    "\n",
    "print (\"Training Set - \", x_train.shape)\n",
    "print (\"Test Set - \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 24930)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating bag of words features.\n",
    "count_vect = CountVectorizer()\n",
    "bow_train = count_vect.fit_transform(x_train['CleanedText'].values)\n",
    "bow_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24930)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_test = count_vect.transform(x_test['CleanedText'].values)\n",
    "bow_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding optimal gamma and C using grdisearch and randomsearch :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing SVC and Gridsearch and Randomsearch\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.1, 1, 10]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "param = [{'C': [10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3], 'gamma':[0.01, 0.1, 1, 10]}]\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using grid search to find optimal C and gamma\n",
    "model1 = GridSearchCV(clf, param)\n",
    "model1.fit(bow_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model1.score(bow_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Conclusions for Bag of Words **\n",
    "* GridSearch gave the value of C as 10 and gamma as 0.01.\n",
    "* Accuracy is - 87.1 %\n",
    "\n",
    "** Using RandomizedSearchCV now **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import randint library to generate distributions.\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_2 = {'C': sp_randint(10**-3, 10**3), 'gamma': sp_randint(10**-1, 10**1)}\n",
    "param_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using randomzied search to find optimal C and gamma\n",
    "model2 = RandomizedSearchCV(clf, param_2)\n",
    "model2.fit(bow_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model2.score(bow_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RandomizedSearchCV results for Bag of Words **\n",
    "* C obtained is 712 and gamma obtained is 2.\n",
    "* Accuracy of model = 81.05 %, approx 6% lower than what was obtained using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating TFIDF features.\n",
    "tfidf = TfidfVectorizer()\n",
    "tf_train = tfidf.fit_transform(x_train['CleanedText'].values)\n",
    "tf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_test = tfidf.transform(x_test['CleanedText'].values)\n",
    "tf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using grid search to find optimal C and gamma\n",
    "model1 = GridSearchCV(clf, param)\n",
    "model1.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting best model\n",
    "model1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score on test data \n",
    "model1.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Conclusions for TFIDF **\n",
    "* GridSearch gave the value of C as 100 and gamma as 0.01.\n",
    "* Accuracy is - 87.1 %, exactly similar to BoW SVC using gridsearchCV\n",
    "\n",
    "** Using RandomizedSearchCV now **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using randomzied search to find optimal C and gamma\n",
    "model2 = RandomizedSearchCV(clf, param_2)\n",
    "model2.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model2.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RandomizedSearchCV results for TFIDF **\n",
    "* C obtained is 532 and gamma obtained is 0 !!!.\n",
    "* Accuracy of model = 81.05 %, approx 6% lower than what was obtained using GridSearchCV\n",
    "\n",
    "\n",
    "** The results obtained from BoW and TFIDF are exactly similar !!!, Same accuracy for gridsearchcv and randomsearchcv **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec :\n",
    "* We will train W2V on our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removing html tags and apostrophes if present.\n",
    "import re\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = sentence.decode('utf-8')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting the train set into clean form which does not contain html tags etc.\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent_train=[]\n",
    "for sent in x_train['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_train.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Doing the same for test dataset.\n",
    "list_of_sent_test=[]\n",
    "for sent in x_test['CleanedText'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent_test.append(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the wor2vec model using train dataset\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent_train,min_count=5,size=200, workers=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg-W2V :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_vectors_train = []; # the avg-w2v for each sentence/review is stored in this train\n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(20) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_train.append(sent_vec)\n",
    "    \n",
    "print (len(sent_vectors_train))\n",
    "print (len(sent_vectors_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this test\n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(20) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)\n",
    "    \n",
    "print (len(sent_vectors_test))\n",
    "print (len(sent_vectors_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch on obtained AVG-W2V data -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using grid search to find optimal C and gamma\n",
    "model1 = GridSearchCV(clf, param)\n",
    "model1.fit(sent_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting best model\n",
    "model1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score on test data \n",
    "model1.score(sent_vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Conclusions for AVG-W2V **\n",
    "* GridSearch gave the value of C as 0.001 and gamma as 0.01.\n",
    "* Accuracy is - 81.05 %\n",
    "\n",
    "** Using RandomizedSearchCV now **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using randomzied search to find optimal C and gamma\n",
    "model2 = RandomizedSearchCV(clf, param_2)\n",
    "model2.fit(sent_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting score on test data\n",
    "model2.score(sent_vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RandomizedSearchCV results for AVG-W2V **\n",
    "* C obtained is 506 and gamma obtained is 0.\n",
    "* Accuracy of model = 81.05 % same as gridsearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF-W2V :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will first create tfidf w2v features.\n",
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_tf_idf = tf_idf_vect.fit_transform(x_train['CleanedText'].values)\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_sent_vectors_train = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent_train: # for each review/sentence\n",
    "    sent_vec = np.zeros(20) # as word vectors are of zero length\n",
    "    weight_sum = 0.0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tfidf)\n",
    "            weight_sum += tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_train.append(sent_vec)\n",
    "    row += 1\n",
    "    \n",
    "print (len(tfidf_sent_vectors_train))\n",
    "print (len(tfidf_sent_vectors_train[0]))\n",
    "print (tfidf_sent_vectors_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent_test: # for each review/sentence\n",
    "    sent_vec = np.zeros(20) # as word vectors are of zero length\n",
    "    weight_sum = 0.0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tfidf)\n",
    "            weight_sum += tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_test.append(sent_vec)\n",
    "    row += 1\n",
    "    \n",
    "print (len(tfidf_sent_vectors_test))\n",
    "print (len(tfidf_sent_vectors_test[0]))\n",
    "print (tfidf_sent_vectors_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using grid search to find optimal C or 1/lamda\n",
    "model1 = GridSearchCV(clf, param)\n",
    "model1.fit(tfidf_sent_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nan values are assigned 0 (if present)\n",
    "tfidf_sent_vectors_test = np.array(tfidf_sent_vectors_test)\n",
    "tfidf_sent_vectors_test = np.nan_to_num(tfidf_sent_vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model1.score(tfidf_sent_vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search Conclusions for TFIDF W2V **\n",
    "* GridSearch gave the value of C as 0.001 and gamma as 0.01.\n",
    "* Accuracy is - 81.05 %\n",
    "\n",
    "** Using RandomizedSearchCV now **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using randomzied search to find optimal C and gamma\n",
    "model2 = RandomizedSearchCV(clf, param_2)\n",
    "model2.fit(tfidf_sent_vectors_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the best model\n",
    "model2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model2.score(tfidf_sent_vectors_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** RandomizedSearchCV results for TFIDF-W2V **\n",
    "* C obtained is 228 and gamma obtained is 0.\n",
    "* Accuracy of model = 81.05 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions :\n",
    "1. Bag of Words and TFIDF model have same accuracy of 87.1 % using GridSearchCV and 81.05 % when using RandomziedSearchCV\n",
    "2. Avg-W2V and TFIDF-W2V also have same accuracy of 81.05 % using both Grid and Random search.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Model</th><th>GridSearch C and Gamma</th><th>RandomSearch C and gamma</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bag of words</td><td>C = 10 , gamma = 0.01</td><td>C = 712, gamma = 2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>TFIDF</td><td>C = 100, gamma = 0.01</td><td> C = 532, gamma = 0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Avg-W2V</td><td>C = 0.001, gamma = 0.01</td><td>C = 506, gamma = 0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Tfidf-W2V</td><td>C = 0.001, gamma = 0.01</td><td>C = 228, gamma = 0</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
